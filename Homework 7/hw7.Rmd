---
title: Homework 7
author: Ansel George
output:
    pdf_document:
        highlight: tango
        latex_engine: xelatex
fontsize: 12pt
mainfont: Roboto
monofont: Ubuntu Mono
---

```{r, message=F}
library(dplyr)
library(tidyr)
library(readr)
library(ggplot2)
library(mvtnorm)

library(ConsensusClusterPlus)

set.seed(10)
```

# Problem 1:

*Instead of using the built-in `kmeans` function, implement your own k-means
algorithm from scratch. Run your algorithm multiple times on a simulated 2-D
dataset that is easy to visualize. Are your k-means results the same? To solve
this problem, implement consensus clustering by resampling 80% of the data and
perform k-means each time.*

```{r}
distance_probs <- function(distances, centroids_idx) {
  if (length(centroids_idx) == 1) {
    pairwise_distances <- distances[,centroids_idx]
  } else {
    pairwise_distances <- apply(distances[,centroids_idx], 1, min)
  }
  return(pairwise_distances/sum(pairwise_distances))
}

assign_cluster <- function(X, centroids) {
  k <- dim(centroids)[1]
  nr <- dim(X)[1]
  nc <- dim(X)[2]

  distances <- matrix(rep(0, nr*k), nrow=nr, ncol=k)
  for (i in 1:k) {
    distances[,i] <- apply(X, 1, f <- function(x) {sum((x - centroids[i])^2)^.5})
  }
  return(apply(distances, 1, which.min))
}

update_centroids <- function(X, assignments, k) {
  nr <- dim(X)[1]
  nc <- dim(X)[2]

  centroids <- matrix(nrow=k, ncol=nc)
  for (i in 1:k) {
    centroids[i,] <- apply(X[assignments == i,], 2, mean)
  }

  return(centroids)
}

kmeans_plusplus <- function(X, k=2, tol=.005) {
  nr <- dim(X)[1]
  nc <- dim(X)[2]

  # Pick initial centroids from data
  all_distances <- as.matrix(dist(X), nrow=nr)
  
  centroids <- matrix(rep(0, k*nc), ncol=nc)
  centroids_idx <- c()
  centroids_idx[1] <- sample(1:nr, 1)
  centroids[1,] <- X[centroids_idx[1],]

  for (i in 2:k) {
    probs <- distance_probs(all_distances, centroids_idx)
    centroids_idx <- append(centroids_idx, sample(1:nr, 1, prob=probs))
    centroids[i,] <- X[centroids_idx[i],]
  }

  # Do the k-means thing.
  error <- tol+1
  assignments <- rep(0, nr)
  counter <- 0
  status <- 0
  while(error > tol) {
    assignments <- assign_cluster(X, centroids)
    new_centroids <- update_centroids(X, assignments, k)
    error <- (sum(new_centroids - centroids)^2)^.5
    centroids <- new_centroids

    if (counter > 100) {
      status <- 1
      break
    }
    counter <- counter + 1
  }

  return(list(centroids=centroids, assignments=assignments, steps=counter, status=status))
}
```

```{r}
N <- 1000

mu1 <- c(0, 0)
Sigma1 <- matrix(c(2, .1, .1, 1), nrow=2, ncol=2)
X1 <- rmvnorm(N, mean=mu1, sigma=Sigma1, method="chol")

mu2 <- c(5, 5)
Sigma2 <- matrix(c(1, .5, .5, 2), nrow=2, ncol=2)
X2 <- rmvnorm(N, mean=mu2, sigma=Sigma2, method="chol")

X <- rbind(X1, X2)

qplot(x=X[,1], y=X[,2])
```

```{r}
k <- 2
res <- kmeans_plusplus(X, k)
res$centroids
```

```{r}
d <- data.frame(cbind(X, res$assignments))
colnames(d) <- c("X", "Y", "cluster")
ggplot(d) + aes(x=X,y=Y,colour=factor(cluster)) + geom_point()
```


# Problem 2:

*Follow the steps in Consensus Clustering Demo, perform consensus clustering on
a publicly available gene expression dataset, and report your findings.*

*For convenience, I uploaded a single-cell RNA-seq dataset of mouse cortical
cells (you can learn more about the data from [this
paper](https://www.nature.com/articles/nn.4216). The data is filtered and now
only contains the top 1000 most variable genes across 1809 cells. Another file
is included with cell labels generated by the paper, so that you can compare
your result with theirs. You can download the files here:
[gene_expression.zip](https://canvas.uchicago.edu/courses/21617/files/2459510/download?wrap=1).*





*Find a public available mRNAseq dataset with at least 250 samples and 5000
genes, perform consensus clustering and report your findings.*

# Background

**Dataset:** Head and Neck Squamous Cell Carcinoma (Primary solid tumor)

\url{http://dx.doi.org/10.7908/C1C828P8}


# Data acquisition and cleanup

First, download the dataset.

```{bash, message=F, warning=F}
./scripts/download2.sh
```

Cleanup the files.

```{r, message=F, warning=F}
metadata <- read_tsv('data/normalized_data.txt', col_names=F, n_max=1)
all_data <- read_tsv('data/normalized_data.txt', skip=1)
# colnames(all_data) <- metadata
```

```{r, message=F, warning=F}
mad_genes <- (all_data %>%
              gather(key, count, -gene_id) %>%
              group_by(gene_id) %>%
              drop_na() %>%
              summarise(mad=mad(count)) %>%
              arrange(desc(mad)))[1:5000,] %>% select(gene_id)
mad_data <- data.matrix(
              inner_join(mad_genes, all_data, by='gene_id') %>% 
                select(-gene_id))
```

```{r}
title <- "HNSC"
res <- ConsensusClusterPlus(mad_data, maxK = 6, reps = 50, pItem = 0.8,
                            pFeature = 1, title = title, clusterAlg = "hc",
                            distance = "pearson", seed = 1262118388.71279,
                            plot = "pdf")
```

```{r}
res[[2]][["consensusMatrix"]][1:5, 1:5]

#consensusTree - hclust object
res[[2]][["consensusTree"]]

#consensusClass - the sample classifications
res[[2]][["consensusClass"]][1:5]

icl = calcICL(res, title=title, plot="pdf")
head(icl[["clusterConsensus"]])

icl[["itemConsensus"]][1:5, ]
```
