\documentclass{beamer}

\mode<presentation>{%
  \usetheme[block=fill,progressbar=frametitle]{metropolis}
  \setsansfont[BoldFont={Fira Sans SemiBold}]{Fira Sans Book}
}

\usepackage{appendixnumberbeamer}
\usepackage[font=tiny]{caption}
\usepackage{graphicx}
\usepackage{pifont}
% \usepackage{booktabs}

\title{Biclustering with heterogeneous variance}
\author{Guanhua Chen, Patrick F. Sullivan, and Michael R. Kosorok}
\date{July 23, 2013}

\begin{document}

\begin{frame}
\titlepage%
\end{frame}

\begin{frame}{Problem}
  How to \textbf{cluster} data using \textbf{relevant factors} while
  \textbf{excluding irrelevant information and noise.}
  \begin{figure}
    \includegraphics[width=\linewidth]{figures/fig1v2.png}
    \caption{Data set contains two clusters determined by two variables $X_1$
      and $X_2$ such that points around $(1,1)$ and $(-1,-1)$ naturally form
      clusters. There are 200 observations (100 for each cluster) and 1,002
      variables ($X_1$, $X_2$ and 1,000 random noise variables). We plot the
      data in the 2D space of $X_1$ and $X_2$. Graphs with true cluster labels
      and predicted cluster labels obtained by clustering using only $X_1$ and
      $X_2$ and clustering by using all variables are laid from left to right.
      The predicted labels are the same as the true labels only when $X_1$ and
      $X_2$ are used for clustering; however, the performance is much worse
      when all variables are used.}
  \end{figure}
\end{frame}

\section{Background}

\begin{frame}{Sparsity}
  \begin{enumerate}
    \item Genotype data is very high-dimensional in terms of features.
    \item Only a subset of features may contribute to a trait.
    \item Formally,
  \end{enumerate}
  \begin{align*}
    \textbf{X} &\approx \textbf{U}\textbf{\Sigma}\textbf{V}^T = \sum_{i=1}^r d_i \textbf{u}_i\textbf{v}_i^T
  \end{align*}

  \begin{equation*}
    \textrm{where }\textbf{X} \in \mathbb{R}^{n \times p}\textrm{, } \textbf{U} \in \mathbb{R}^{n \times r}\textrm{, } \textbf{V} \in \mathbb{R}^{r \times p}\textrm{, } \textbf{\Sigma} \in \mathbb{R}^{r \times r}\textrm{, and } r \ll \textrm{rank}(\textbf{X})
  \end{equation*}
\end{frame}

\begin{frame}{Biclustering}
  \begin{enumerate}
    \item Rather than cluster features in sample-space or samples in feature
      space, cluster both simultaneously.
    \item Clusters may correspond to sources with heterogeneous variance.
  \end{enumerate}
  \begin{align*}
    \textbf{X} &= \textbf{\Xi} + \textbf{\Phi}
  \end{align*}
\end{frame}

\begin{frame}{Biclustering demo}
  Few slides with a biclustering demonstration for some random sparse matrix.
\end{frame}

\begin{frame}{Sparsity + biclustering = \ding{170}}
  \begin{enumerate}
    \item Finding optimal set of biclusters is NP-Complete.
      \begin{itemize}
        \item Computationally expensive
      \end{itemize}
    \item Algorithms are unsupervised.
      \begin{itemize}
        \item Difficult to tell if solution is optimal
        \item Often resort to different clustering methods and majority voting
          (even more expensive!)
      \end{itemize}
    \item \textbf{Nifty trick:} for sparse matrices, SVD can compute biclusters
      without the need for matrix permutations.
  \end{enumerate}
\end{frame}

\begin{frame}{Sparse SVD (SSVD) Trick}
  \begin{enumerate}
    \item SSVD computes sparse singular vectors.
    \item Submatrices are generated by outer products of singular vectors.
      \begin{itemize}
        \item Orthogonality and sparsity reduce overlap among submatrices.
        \item Submatrices correspond to biclusters.
      \end{itemize}
  \end{enumerate}
\end{frame}

\section{Model}

\begin{frame}{Model}
  \begin{block}{HSSVD}
    Heterogeneous sparse singular value decomposition
  \end{block}
  \begin{enumerate}
    \item SSVD and other methods cluster around means.
    \item Cancer genetic and epigenetic patterns can be characterized by means
      \textbf{and} variance.
    \item HSSVD modifies the SSVD algorithm to use both for computing
      biclusters.
  \end{enumerate}
  \begin{align*}
    \textbf{X} &= \textbf{\Xi} + \rho^2 \textbf{\Sigma} \times \textbf{\Phi} + b\textbf{J}
  \end{align*}
\end{frame}

\section{Results}

\begin{frame}{Hypervariation of Methylation in Cancer (I)}
  \begin{figure}
    \includegraphics[width=\linewidth]{figures/fig2.png}
    \caption{Mean approximation of colon cancer and the normal matched samples.
      From left to right the methods are HSSVD, FIT-SSVD, and LSHM\@. Colon
      cancer samples are labeled in blue, and normal matched samples are labeled
      in pink in the sidebar.}
  \end{figure}
\end{frame}

\begin{frame}{Hypervariation of Methylation in Cancer (II)}
  \begin{figure}
    \includegraphics[width=\linewidth]{figures/fig3.png}
    \caption{HSSVD approximation result for all samples. (A) Variance
      approximation; (B) mean approximation. Blue represents cancer samples,
      and pink rep- resents normal samples in the sidebar. Genes and samples
      are ordered by hierarchical clustering. Red represents large values, and
      green represents small values. Only the variance approximation can
      discriminate between cancer and normal samples. More importantly, within
      the same gene, the heatmap for the variance approximation indicates that
      cancer patients have larger variance than normal individuals. This result
      matches the conclusion in ref. 19. In addition, the cDMRs with the
      greatest contrast variance across cancer and normal samples are
      highlighted by the variance approximation, whereas the original paper
      does not provide such information.}
  \end{figure}
\end{frame}

\begin{frame}{Gene Expression in Lung Cancer}
  \begin{figure}
    \includegraphics[height=.6\textheight,keepaspectratio]{figures/fig4.png}
    \caption{Checkerboard plots for four methods. We plot the rank-three
      approximation for each method. Within each image, samples are laid in
      rows, and genes are in columns. We order the samples by subtype for all
      images (top to bottom: carcinoid, colon, normal, and small cell), and
      different subtypes are separated by white lines. Genes are sorted by the
      estimated second right singular vector ($\hat{u}_2$), and we only
      included genes that are in the support (defined in Table 1). Across all
      methods, the HSSVD and FIT-SSVD methods provide the clearest block
      structure reflecting biclusters.}
  \end{figure}
\end{frame}

\begin{frame}{Simulated Data}
  \begin{figure}
  \includegraphics[width=\linewidth,keepaspectratio]{figures/table2.png}
  \end{figure}
\end{frame}

\begin{frame}[label=end, standout]
\end{frame}

\appendix

\begin{frame}{LSHM}
\end{frame}

\begin{frame}{FIT-SSVD}
\end{frame}

\end{document}
